{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook provides an example schema to follow, when merging data to the gazetteer with feature records. In this script we are merging data from Geonames. The same script can be used to load data from other sources such as OpenStreetMap. Change the field names accordingly to your datasource when loading data from other source.",
   "id": "cf0b7b398cf538c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Connect to the database",
   "id": "3ed9c2dcbe5e6d9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    database = \"biowhere-gazetteer\",\n",
    "    user = \"postgres\",\n",
    "    host = \"127.0.0.1\",\n",
    "    password = \"<password>\",\n",
    "    port = 1234)\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load geonames to postgresql table using CSV\n",
    "Geonames data for New Zealand can be downloaded from [here](https://download.geonames.org/export/dump/)"
   ],
   "id": "a3384cae8536b25c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "\n",
    "# Load the CSV file into a GeoDataFrame and generate the 'geometry' column\n",
    "gdf = gpd.read_file('./path/to/geonames.csv')\n",
    "gdf['geometry'] = gpd.points_from_xy(gdf.longitude, gdf.latitude, crs=\"EPSG:4326\")\n",
    "\n",
    "# Define database connection details\n",
    "db_url = \"postgresql://postgres:<password>@localhost:<port>/biowhere-gazetteer\"\n",
    "table_name = \"geonames\"\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Use GeoAlchemy2 to prepare geometries for PostGIS\n",
    "gdf['geometry'] = gdf['geometry'].apply(lambda geom: WKTElement(geom.wkt, srid=4326))\n",
    "\n",
    "# Rename the 'geometry' column to match PostGIS conventions\n",
    "gdf = gdf.rename(columns={'geometry': 'geom'})\n",
    "\n",
    "# Write the GeoDataFrame to PostGIS\n",
    "gdf.to_sql(\n",
    "    table_name,\n",
    "    engine,\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    dtype={'geom': Geometry('POINT', srid=4326)}\n",
    ")\n",
    "\n",
    "print(f\"Data successfully written to the '{table_name}' table in PostGIS.\")"
   ],
   "id": "e8905b765bb55bbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Normalize geonames feature codes to detect duplicates",
   "id": "37f450cea62fabca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Mapping GeoNames feature codes to more common feature types with associated feature classes\n",
    "GEONAMES_FEATURE_CODE_MAPPING = {\n",
    "    # Administrative (A)\n",
    "    'ADM1': 'First-order Administrative Division',\n",
    "    'ADM2': 'Second-order Administrative Division',\n",
    "    'ADM3': 'Third-order Administrative Division',\n",
    "    'ADM4': 'Fourth-order Administrative Division',\n",
    "    'ADMD': 'Administrative Division',\n",
    "\n",
    "    # Populated places (P)\n",
    "    'PPL': 'Populated Place',\n",
    "    'PPLA':'Seat of a First-order Administrative Division',\n",
    "    'PPLC': 'Capital of a Political Entity',\n",
    "    'PPLF': 'Farm Village',\n",
    "\n",
    "    # Hydrographic (H)\n",
    "    'STM': 'Stream',\n",
    "    'LKE': 'Lake',\n",
    "    'PND': 'Pond',\n",
    "    'CNLA': 'Artificial Canal',\n",
    "\n",
    "    # Terrain (T)\n",
    "    'MT': 'Mountain',\n",
    "    'HLL': 'Hill',\n",
    "    'PK': 'Peak',\n",
    "    'VAL': 'Valley',\n",
    "\n",
    "    # Spot features (S)\n",
    "    'AIRP': 'Airport',\n",
    "    'SCH': 'School',\n",
    "    'HSP': 'Hospital',\n",
    "    'CH': 'Church',\n",
    "}\n",
    "\n",
    "# Mapping feature class codes to normalized names\n",
    "GEONAMES_FEATURE_CLASS_MAPPING = {\n",
    "    'A': 'Administrative Region',\n",
    "    'H': 'Hydrographic',\n",
    "    'L': 'Area',\n",
    "    'P': 'Populated Place',\n",
    "    'R': 'Road / Railroad',\n",
    "    'S': 'Spot Feature',\n",
    "    'T': 'Terrain',\n",
    "    'U': 'Undersea',\n",
    "    'V': 'Vegetation'\n",
    "}\n",
    "\n",
    "def normalize_feature_code(feature_code, feature_class=None):\n",
    "    \"\"\"\n",
    "    Normalize a GeoNames feature code into a human-readable feature type.\n",
    "    If the feature code is not found, use the feature class to derive the normalized class.\n",
    "\n",
    "    Parameters:\n",
    "        feature_code (str): GeoNames feature code.\n",
    "        feature_class (str, optional): GeoNames feature class code.\n",
    "\n",
    "    Returns:\n",
    "        str: Normalized feature description\n",
    "    \"\"\"\n",
    "    if feature_code in GEONAMES_FEATURE_CODE_MAPPING:\n",
    "        return GEONAMES_FEATURE_CODE_MAPPING.get(feature_code)\n",
    "    elif feature_class:\n",
    "        return GEONAMES_FEATURE_CLASS_MAPPING.get(feature_class)\n",
    "    else:\n",
    "        return feature_code"
   ],
   "id": "a8f15952ef07f957"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Identify the duplicates records with current gazetteer entries\n",
   "id": "aaee7aa3c81d2a83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def query_nearby_geometries(cur, geometry_wkt):\n",
    "    \"\"\"\n",
    "    Queries all spatial tables for geometries within radius_km of the given WKT geometry.\n",
    "    \"\"\"\n",
    "    radius_km = 2\n",
    "    tables = [\n",
    "        \"SpatialGeometryRepresentation_point\",\n",
    "        \"SpatialGeometryRepresentation_line\",\n",
    "        \"SpatialGeometryRepresentation_polygon\",\n",
    "    ]\n",
    "    all_results = []\n",
    "    for table in tables:\n",
    "        query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM {table}\n",
    "            WHERE ST_Distance(\n",
    "                ST_Centroid(geometry)::geography,\n",
    "                ST_Centroid(ST_GeomFromText(%s, 4326))::geography\n",
    "            ) < %s\n",
    "        \"\"\"\n",
    "        cur.execute(query, (geometry_wkt, radius_km * 1000))\n",
    "        all_results.extend(cur.fetchall())\n",
    "    return all_results\n"
   ],
   "id": "9453a7fb07a71403"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fetch_feature_infor_from_name(cur, name):\n",
    "    records = []\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT feature_id FROM FeatureName WHERE featurename = %s\n",
    "    \"\"\", (name,))\n",
    "    feature_ids = cur.fetchall()\n",
    "    for feature_id in feature_ids:\n",
    "        feature_id = feature_id[0]\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT featureclass FROM FeatureType WHERE feature_id = %s\n",
    "        \"\"\", (feature_id,))\n",
    "        feature_type_row = cur.fetchone()\n",
    "        feature_class = feature_type_row[0] if feature_type_row else None\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT id FROM SpatialGeometryRepresentation WHERE feature_id = %s\n",
    "        \"\"\", (feature_id,))\n",
    "        geometry_id = cur.fetchone()[0]\n",
    "        geometry = None\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT geometry FROM SpatialGeometryRepresentation_point WHERE spatialgeometryrepresentation_id = %s\n",
    "        \"\"\", (geometry_id,))\n",
    "        result = cur.fetchone()\n",
    "        if result and result[0]:\n",
    "            geometry = load_wkb(bytes.fromhex(result[0]))\n",
    "\n",
    "        if geometry is None:\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT geometry FROM SpatialGeometryRepresentation_polygon WHERE spatialgeometryrepresentation_id = %s\n",
    "            \"\"\", (geometry_id,))\n",
    "            result = cur.fetchone()\n",
    "            if result and result[0]:\n",
    "                geometry = load_wkb(bytes.fromhex(result[0]))\n",
    "\n",
    "        if geometry is None:\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT geometry FROM SpatialGeometryRepresentation_line WHERE spatialgeometryrepresentation_id = %s\n",
    "            \"\"\", (geometry_id,))\n",
    "            result = cur.fetchone()\n",
    "            if result and result[0]:\n",
    "                geometry = load_wkb(bytes.fromhex(result[0]))\n",
    "        if geometry:\n",
    "            centroid = geometry.centroid\n",
    "            coords = (centroid.y, centroid.x)\n",
    "            latitude = coords[0]\n",
    "            longitude = coords[1]\n",
    "            records.append((feature_id, feature_class, geometry, latitude, longitude))\n",
    "    # print(f\"records: {records}\")\n",
    "    return records"
   ],
   "id": "885012e5b6461c41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fetch_feature_info(cur, geometry_id):\n",
    "        \"\"\"\n",
    "        Fetches feature_id, name, and category info for a given geometry ID.\n",
    "        \"\"\"\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT feature_id FROM SpatialGeometryRepresentation WHERE id = %s\n",
    "        \"\"\", (geometry_id,))\n",
    "        feature_id = cur.fetchone()[0]\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT featureClass FROM FeatureType WHERE feature_id = %s\n",
    "        \"\"\", (feature_id,))\n",
    "        feature_class = cur.fetchone()[0]\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT featureName FROM FeatureName WHERE feature_id = %s\n",
    "        \"\"\", (feature_id,))\n",
    "        feature_name = cur.fetchone()[0]\n",
    "\n",
    "        return feature_id, feature_class, feature_name"
   ],
   "id": "8fd2f0e549c1903c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import subprocess\n",
    "import os\n",
    "from shapely.wkb import loads as load_wkb\n",
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def check_duplicates_with_geonames(rows, batch_num):\n",
    "    \"\"\"\n",
    "    For each geonames record, queries nearby spatial geometries within a specified radius,\n",
    "    extracts attributes, and performs duplicate detection using a downstream prediction script.\n",
    "    \"\"\"\n",
    "    all_predictions_df = pd.DataFrame()\n",
    "    all_duplicates_df = pd.DataFrame()\n",
    "    data_records = []\n",
    "    for count, row in enumerate(rows, start=1):\n",
    "        print(f\"Processing row {count}: {row}\")\n",
    "\n",
    "        geonameid, name, alternatenames, feature_class, feature_code, geometry_hex, latitude, longitude = row\n",
    "        left_geometry = load_wkb(bytes.fromhex(geometry_hex))\n",
    "        left_coords = (latitude, longitude)\n",
    "        left_category = normalize_feature_code(feature_code, feature_class)\n",
    "\n",
    "        with conn.cursor() as cur:\n",
    "            nearby_records = query_nearby_geometries(cur, left_geometry.wkt)\n",
    "            print(f\"Found {len(nearby_records)} nearby records.\")\n",
    "\n",
    "            for record in nearby_records:\n",
    "                record_geometry = load_wkb(bytes.fromhex(record[2]))\n",
    "                centroid = record_geometry.centroid\n",
    "                right_coords = (centroid.y, centroid.x)\n",
    "\n",
    "                distance_km = (\n",
    "                    geodesic(left_coords, right_coords).kilometers\n",
    "                    if None not in left_coords and None not in right_coords\n",
    "                    else None\n",
    "                )\n",
    "\n",
    "                feature_id, right_category, right_name = fetch_feature_info(cur, record[5])\n",
    "\n",
    "                data_records.append({\n",
    "                    \"geonameid\": geonameid,\n",
    "                    \"feature_id\": feature_id,\n",
    "                    \"left_name\": name,\n",
    "                    \"left_category\": left_category,\n",
    "                    \"left_geometry\": left_geometry,\n",
    "                    \"left_latitude\": latitude,\n",
    "                    \"left_longitude\": longitude,\n",
    "                    \"right_name\": right_name,\n",
    "                    \"right_category\": right_category,\n",
    "                    \"right_geometry\": record_geometry,\n",
    "                    \"right_latitude\": right_coords[0],\n",
    "                    \"right_longitude\": right_coords[1],\n",
    "                    \"distance_km\": distance_km\n",
    "                })\n",
    "\n",
    "            existing_keys = set(\n",
    "                (r[\"feature_id\"], r[\"right_name\"])\n",
    "                for r in data_records\n",
    "            )\n",
    "            similar_name_records = fetch_feature_infor_from_name(cur, name)\n",
    "            print(f\"Found {len(similar_name_records)} similar name records.\")\n",
    "            for record in similar_name_records:\n",
    "                feature_id, right_category, right_geometry, right_latitude, right_longitude = record\n",
    "                right_coords = (right_latitude, right_longitude)\n",
    "                distance_km = (\n",
    "                    geodesic(left_coords, right_coords).kilometers\n",
    "                    if None not in left_coords and None not in right_coords\n",
    "                    else None\n",
    "                )\n",
    "\n",
    "                data_records.append({\n",
    "                    \"geonameid\": geonameid,\n",
    "                    \"feature_id\": feature_id,\n",
    "                    \"left_name\": name,\n",
    "                    \"left_category\": left_category,\n",
    "                    \"left_geometry\": left_geometry,\n",
    "                    \"left_latitude\": latitude,\n",
    "                    \"left_longitude\": longitude,\n",
    "                    \"right_name\": name,\n",
    "                    \"right_category\": right_category,\n",
    "                    \"right_geometry\": right_geometry,\n",
    "                    \"right_latitude\": right_latitude,\n",
    "                    \"right_longitude\": right_longitude,\n",
    "                    \"distance_km\": distance_km\n",
    "                })\n",
    "\n",
    "    # Save input data\n",
    "    df_input = pd.DataFrame(data_records)\n",
    "    # print(df_input)\n",
    "    input_pkl = f\"tmp/{batch_num}_input.pkl\"\n",
    "    df_input.to_pickle(input_pkl)\n",
    "    # df_input.to_csv(f\"tmp/{batch_num}_input.csv\")\n",
    "\n",
    "    # Run the prediction script\n",
    "    output_pkl = f\"tmp/{batch_num}_output.pkl\"\n",
    "    predict_command = (\n",
    "        f\"python predict.py \"\n",
    "        f\"--input_file {input_pkl} \"\n",
    "        f\"--output_file {output_pkl} \"\n",
    "        f\"--input_crs epsg:4326 \"\n",
    "        f\"--use_crs epsg:3857 \"\n",
    "        f\"--run_att_aff \"\n",
    "        f\"--device cpu \"\n",
    "        f\"--language_model bert\"\n",
    "    )\n",
    "    try:\n",
    "        # Run the command with subprocess and capture output\n",
    "        result = subprocess.run(\n",
    "            predict_command,\n",
    "            check=True,\n",
    "            timeout=1000,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Batch {batch_num}: Prediction script timed out after 360 seconds\")\n",
    "        return False\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Batch {batch_num}: Prediction script failed with exit code {e.returncode}\")\n",
    "        print(\"Error output:\")\n",
    "        print(e.stderr)\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Batch {batch_num}: Unexpected error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "    # Load and process prediction results\n",
    "    if os.path.exists(output_pkl):\n",
    "        df_output = pd.read_pickle(output_pkl)\n",
    "        all_predictions_df = pd.concat([all_predictions_df, df_output], ignore_index=True)\n",
    "\n",
    "        duplicates_df = df_output[df_output['prediction'] == 1]\n",
    "        if duplicates_df.empty:\n",
    "            print(\"No duplicates found.\")\n",
    "        else:\n",
    "            print(\"Duplicates detected.\")\n",
    "            all_duplicates_df = pd.concat([all_duplicates_df, duplicates_df], ignore_index=True)\n",
    "    else:\n",
    "        print(\"Prediction output file not found.\")\n",
    "\n",
    "    # Save results\n",
    "    file_to_save = f\"tmp/{batch_num}_prediction.csv\"\n",
    "    all_duplicates_df.to_csv(file_to_save, index=False)\n",
    "    return None"
   ],
   "id": "865d733a6b3b1f9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BATCH_SIZE = 1000\n",
    "\n",
    "# Step 1: Execute a single query to get up to 10,000 rows in order\n",
    "cur.execute(\"\"\"\n",
    "    SELECT geonameid, name, alternatenames, feature_class, feature_code, geom, latitude, longitude\n",
    "    FROM geonames_manawatu\n",
    "    ORDER BY geonameid\n",
    "\"\"\")\n",
    "batch_num = 1\n",
    "\n",
    "# Step 2: Process in batches of 1,000\n",
    "# Processing as batches due to the limitations in duplicate detection algorithm\n",
    "while True:\n",
    "    batch = cur.fetchmany(BATCH_SIZE)\n",
    "    if batch_num != 13:\n",
    "        batch_num += 1\n",
    "        continue\n",
    "    if not batch:\n",
    "        break\n",
    "    # batch = batch[:-1]\n",
    "    print(f\"Processing the {(batch_num)} batch...\")\n",
    "    check_duplicates_with_geonames(batch, batch_num)\n",
    "    batch_num += 1\n",
    "    break\n",
    "\n",
    "print(\"Finished processing.\")\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# Merge csvs with duplicates together\n",
    "df1 = pd.read_csv('tmp/1_predictions.csv')\n",
    "df2 = pd.read_csv('tmp/2_predictions.csv')\n",
    "df3 = pd.read_csv('tmp/3_predictions.csv')\n",
    "duplicates = pd.concat([df1, df2, df3])"
   ],
   "id": "8a0bf2eae187172c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Merge records from Geonames to the gazetteer",
   "id": "60a2532fb865adfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load records from GeoNames",
   "id": "b3b32c4c8a033fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connection setup\n",
    "engine = create_engine(\"postgresql://postgres:<password>@127.0.0.1:<port>/biowhere-gazetteer\")\n",
    "\n",
    "# Read the geonames source table into a DataFrame\n",
    "geonames_df = pd.read_sql(\"SELECT * FROM geonames\", engine)"
   ],
   "id": "a2d94dc499bc525a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Filter the new records and records that refer to existing features in the gazetteer",
   "id": "c92702e46449793a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "duplicate_ids = set(duplicates['geonameid'])\n",
    "duplicate_ids = set(str(x) for x in duplicate_ids)\n",
    "\n",
    "print(f\"Number of geonames records: {len(geonames_df)}\")\n",
    "\n",
    "df_duplicates = geonames_df[geonames_df['geonameid'].isin(duplicate_ids)]\n",
    "df_new = geonames_df[~geonames_df['geonameid'].isin(duplicate_ids)]\n",
    "\n",
    "print(f\"Number of duplicates: {len(df_duplicates)}\")\n",
    "print(f\"Number of new records: {len(df_new)}\")"
   ],
   "id": "942dcafa12d0ae15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Merge data from Geonames to the gazetteer",
   "id": "34e9a5819deea819"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Get the Maori name of a place if present\n",
    "def get_geonames_maori_name(geonames_id):\n",
    "    base_url = \"http://api.geonames.org/get\"\n",
    "    feature_id = geonames_id\n",
    "    username = \"quaketext\"\n",
    "    style = \"FULL\"\n",
    "    params = {\"lang\": \"en\"}\n",
    "    url = f\"{base_url}?geonameId={feature_id}&username={username}&style={style}\"\n",
    "    if params:\n",
    "        url += \"&\" + \"&\".join(f\"{key}={value}\" for key, value in params.items())\n",
    "\n",
    "    response = requests.get(url)\n",
    "    mi_name = ''\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        xml_data = response.text\n",
    "        root = ET.fromstring(xml_data)\n",
    "        mi_name = root.find(\".//alternateName[@lang='mi']\")\n",
    "        if mi_name!=None:\n",
    "            mi_name = mi_name.text\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.reason}\")\n",
    "    return mi_name"
   ],
   "id": "ecb1d9a6656ab990"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Add new features from Geonames",
   "id": "46d22194ed61bada"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_geonames_data(df_batch):\n",
    "    for index, row in df_batch.iterrows():\n",
    "        print(f\"Processing row {index} with geonameid {row['geonameid']}\")\n",
    "        # Add feature\n",
    "        cur.execute(\"INSERT INTO Feature (featureDescription, inferredFlag, lastUpdateDate, lastUpdateUser) VALUES (NULL, NULL, current_timestamp, 'AF') RETURNING id\")\n",
    "        feature_id = cur.fetchone()[0]\n",
    "        print(f\"  Inserted Feature with id: {feature_id}\")\n",
    "\n",
    "        # Set feature name\n",
    "        maori_name = get_geonames_maori_name(row['geonameid'])\n",
    "        if maori_name:\n",
    "            cur.execute(\"INSERT INTO FeatureName (featureName, language, lastUpdateDate, lastUpdateUser, feature_id) VALUES (%s, 'mi', current_timestamp, 'AF', %s) \" \"RETURNING id\", (maori_name, feature_id))\n",
    "            print(f\"  Inserted Maori FeatureName: {maori_name}\")\n",
    "            feature_name_id = cur.fetchone()[0]\n",
    "        elif row['name'] != maori_name:\n",
    "            cur.execute(\"INSERT INTO FeatureName (featureName, language, lastUpdateDate, lastUpdateUser, feature_id) VALUES (%s, NULL, current_timestamp, 'AF', %s) \" \"RETURNING id\", (row['name'], feature_id))\n",
    "            print(f\"  Inserted default FeatureName: {row['name']}\")\n",
    "            feature_name_id = cur.fetchone()[0]\n",
    "\n",
    "        # set geometry\n",
    "        cur.execute(\"INSERT INTO SpatialGeometryRepresentation (lastUpdateDate, lastUpdateUser, timePeriod, spatialAccuracy, feature_id, localityDescription_id) VALUES (current_timestamp, 'AF', NULL, NULL, %s, NULL) RETURNING id\", ( feature_id,))\n",
    "        spatial_geometry_representation_id = cur.fetchone()[0]\n",
    "        print(f\"  Inserted SpatialGeometryRepresentation with id: {spatial_geometry_representation_id}\")\n",
    "\n",
    "        sql = f\"INSERT INTO spatialgeometryrepresentation_point (geodeticReferenceSystem, geometry, lastUpdateDate, lastUpdateUser, spatialGeometryRepresentation_id) VALUES (%s, %s, current_timestamp, 'AF', %s)\"\n",
    "        cur.execute(sql, ('EPSG 4326', row['geom'], spatial_geometry_representation_id))\n",
    "        print(\"  Inserted geometry with EPSG 4326\")\n",
    "\n",
    "        # type\n",
    "        print(f\"feature class : {row['feature_class']}, feature code: {row['feature_code']}\")\n",
    "        fclass = row['feature_class']\n",
    "        fcode = row['feature_code']\n",
    "        feature_type = normalize_feature_code(fcode, fclass)\n",
    "        cur.execute(\"INSERT INTO FeatureType (classificationScheme, featureClass, feature_id, lastUpdateDate, lastUpdateUser) VALUES ('geonames_feature_class', %s, %s, current_timestamp, 'AF') RETURNING id\", (feature_type, feature_id))\n",
    "        feature_type_id = cur.fetchone()[0]\n",
    "        print(f\"  Inserted FeatureType with class: {feature_type}\")\n",
    "\n",
    "\n",
    "        # source\n",
    "        cur.execute(\"INSERT INTO Source (externalSourceId, source, spatialGeometryRepresentation_id, featureType_id, featureName_id, localityDescription_id, lastUpdateDate, lastUpdateUser) VALUES (%s, 'Geonames', %s, %s, %s, NULL, current_timestamp, 'AF')\", (row['geonameid'], spatial_geometry_representation_id, feature_type_id, feature_name_id))\n",
    "        print(f\"  Inserted Source for geonameid: {row['geonameid']}\")\n",
    "\n",
    "        print(f\"Finished processing row {index}\\n\")\n",
    "    conn.commit()\n",
    "    print(\"changes commited to the database.\\n\")"
   ],
   "id": "be61eae7139f8d33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "add_geonames_data(df_new)\n",
   "id": "b2f375b67101f0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Merge data from geonames to the existing features",
   "id": "fdc9f54583dc7cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_geonames_data_duplicate(df_duplicates):\n",
    "    for index, row in df_duplicates.iterrows():\n",
    "        try:\n",
    "            print(f\"---\\nProcessing row {index} with geonameid {row['geonameid']}\")\n",
    "            geoname_id = row['geonameid']\n",
    "            feature_name_id = None\n",
    "\n",
    "            duplicate_entry = duplicates[duplicates['geonameid'] == int(geoname_id)]\n",
    "\n",
    "            if duplicate_entry.empty:\n",
    "                print(f\"Warning: No matching feature found for geonameid {geoname_id}\")\n",
    "                continue\n",
    "\n",
    "            feature_id = str(duplicate_entry.iloc[0]['feature_id'])\n",
    "            print(f\"Found existing feature_id: {feature_id}\")\n",
    "\n",
    "            # Check for existing feature name\n",
    "            cur.execute(\"SELECT featurename FROM FeatureName WHERE feature_id = %s\", (str(feature_id),))\n",
    "            featurename_row = cur.fetchone()\n",
    "            print(f\"Existing FeatureName row: {featurename_row}\")\n",
    "\n",
    "            if not featurename_row or featurename_row[0] != row['name']:\n",
    "                print(f\"Inserting new FeatureName: {row['name']}\")\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO FeatureName (featureName, language, lastUpdateDate, lastUpdateUser, feature_id)\n",
    "                    VALUES (%s, NULL, current_timestamp, 'AF', %s)\n",
    "                    RETURNING id\n",
    "                \"\"\", (row['name'], feature_id))\n",
    "                feature_name_id = cur.fetchone()[0]\n",
    "            else:\n",
    "                print(\"FeatureName already exists and matches the name. Skipping insert.\")\n",
    "\n",
    "            # Add Māori name if available\n",
    "            maori_name = get_geonames_maori_name(geoname_id)\n",
    "            if maori_name:\n",
    "                cur.execute(\"\"\"\n",
    "                    SELECT id FROM FeatureName\n",
    "                    WHERE featureName = %s AND feature_id = %s\n",
    "                \"\"\", (maori_name, feature_id))\n",
    "                maori_name_existed = cur.fetchone()\n",
    "                if not maori_name_existed:\n",
    "                    print(f\"Inserting Māori name: {maori_name}\")\n",
    "                    cur.execute(\"\"\"\n",
    "                        INSERT INTO FeatureName (featureName, language, lastUpdateDate, lastUpdateUser, feature_id)\n",
    "                        VALUES (%s, 'mi', current_timestamp, 'AF', %s)\n",
    "                        RETURNING id\n",
    "                    \"\"\", (maori_name, feature_id))\n",
    "                    feature_name_id = cur.fetchone()[0]\n",
    "                else:\n",
    "                    print(\"Māori name already exists. Skipping insert.\")\n",
    "\n",
    "            # Insert FeatureType\n",
    "            normalize_feature_code = normalize_feature_code(row['feature_code'], row['feature_class'])\n",
    "            print(f\"Inserting FeatureType: {normalize_feature_code}\")\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO FeatureType (classificationScheme, featureClass, feature_id, lastUpdateDate, lastUpdateUser)\n",
    "                VALUES ('geonames_feature_class', %s, %s, current_timestamp, 'AF')\n",
    "                RETURNING id\n",
    "            \"\"\", (normalize_feature_code, feature_id))\n",
    "            feature_type_id = cur.fetchone()[0]\n",
    "\n",
    "            # Check and insert SpatialGeometryRepresentation if needed\n",
    "            print(\"Checking for existing spatial geometry...\")\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT sgr.id\n",
    "                FROM SpatialGeometryRepresentation_point sgrp\n",
    "                JOIN SpatialGeometryRepresentation sgr\n",
    "                    ON sgrp.spatialGeometryRepresentation_id = sgr.id\n",
    "                WHERE sgr.feature_id = %s AND sgrp.geometry = %s\n",
    "            \"\"\", (feature_id, row['geom']))\n",
    "            spatial_geometry_representation_id = None\n",
    "            existing_geometry = cur.fetchone()\n",
    "\n",
    "            if existing_geometry:\n",
    "                print(\"Spatial geometry already exists.\")\n",
    "            else:\n",
    "                print(\"Inserting new spatial geometry representation.\")\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO SpatialGeometryRepresentation\n",
    "                    (lastUpdateDate, lastUpdateUser, timePeriod, spatialAccuracy, feature_id, localityDescription_id)\n",
    "                    VALUES (current_timestamp, 'AF', NULL, NULL, %s, NULL)\n",
    "                    RETURNING id\n",
    "                \"\"\", (feature_id,))\n",
    "                spatial_geometry_representation_id = cur.fetchone()[0]\n",
    "\n",
    "                cur.execute(\"\"\"\n",
    "                    INSERT INTO SpatialGeometryRepresentation_point\n",
    "                    (geodeticReferenceSystem, geometry, lastUpdateDate, lastUpdateUser, spatialGeometryRepresentation_id)\n",
    "                    VALUES (%s, %s, current_timestamp, 'AF', %s)\n",
    "                \"\"\", ('EPSG 4326', row['geom'], spatial_geometry_representation_id))\n",
    "\n",
    "            # Insert into Source\n",
    "            print(\"Inserting Source entry.\")\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO Source\n",
    "                (externalSourceId, source, spatialGeometryRepresentation_id, featureType_id, featureName_id, localityDescription_id, lastUpdateDate, lastUpdateUser)\n",
    "                VALUES (%s, 'Geonames', %s, %s, %s, NULL, current_timestamp, 'AF')\n",
    "            \"\"\", (geoname_id, spatial_geometry_representation_id, feature_type_id, feature_name_id))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index} (geonameid {row['geonameid']}): {e}\")\n",
    "    conn.commit()"
   ],
   "id": "1faf96ff450be2b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "add_geonames_data_duplicate(df_duplicates)\n",
    "cur.close()\n",
    "conn.close()"
   ],
   "id": "79b4a8009ed32007"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
